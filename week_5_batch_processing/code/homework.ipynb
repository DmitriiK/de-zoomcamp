{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "00bc6543",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pyspark\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql import types"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "cd4a0f3d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting default log level to \"WARN\".\n",
      "To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/03/04 16:18:35 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n",
      "23/03/04 16:18:36 WARN Utils: Service 'SparkUI' could not bind on port 4040. Attempting port 4041.\n"
     ]
    }
   ],
   "source": [
    "spark = SparkSession.builder \\\n",
    "    .master(\"local[*]\") \\\n",
    "    .appName('test') \\\n",
    "    .getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "eb3e4c36",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'3.3.2'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spark.version"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5236cebd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-rw-rw-r-- 1 Dmitrii_Kalmanovich Dmitrii_Kalmanovich 878M Dec 20 00:13 fhvhv_tripdata_2021-06.csv\r\n"
     ]
    }
   ],
   "source": [
    "!ls -lh fhvhv_tripdata_2021-06.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0a3399a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "schema = types.StructType([    \n",
    "    types.StructField('dispatching_base_num', types.StringType(), True),\n",
    "    types.StructField('pickup_datetime', types.TimestampType(), True),\n",
    "    types.StructField('dropoff_datetime', types.TimestampType(), True),\n",
    "    types.StructField('PULocationID', types.IntegerType(), True),\n",
    "    types.StructField('DOLocationID', types.IntegerType(), True),\n",
    "    types.StructField('SR_Flag', types.StringType(), True),\n",
    "    types.StructField('Affiliated_base_number', types.StringType(), True)\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "68bc8b72",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+-------------------+-------------------+------------+------------+-------+----------------------+\n",
      "|dispatching_base_num|    pickup_datetime|   dropoff_datetime|PULocationID|DOLocationID|SR_Flag|Affiliated_base_number|\n",
      "+--------------------+-------------------+-------------------+------------+------------+-------+----------------------+\n",
      "|              B02764|2021-06-01 00:02:41|2021-06-01 00:07:46|         174|          18|      N|                B02764|\n",
      "|              B02764|2021-06-01 00:16:16|2021-06-01 00:21:14|          32|         254|      N|                B02764|\n",
      "|              B02764|2021-06-01 00:27:01|2021-06-01 00:42:11|         240|         127|      N|                B02764|\n",
      "|              B02764|2021-06-01 00:46:08|2021-06-01 00:53:45|         127|         235|      N|                B02764|\n",
      "|              B02510|2021-06-01 00:45:42|2021-06-01 01:03:33|         144|         146|      N|                  null|\n",
      "|              B02510|2021-06-01 00:18:15|2021-06-01 00:25:47|          49|          17|      N|                  null|\n",
      "|              B02510|2021-06-01 00:33:06|2021-06-01 00:42:46|          49|         225|      N|                  null|\n",
      "|              B02510|2021-06-01 00:46:27|2021-06-01 00:56:50|         225|         177|      N|                  null|\n",
      "|              B02764|2021-06-01 00:48:06|2021-06-01 01:04:10|         209|          45|      N|                B02764|\n",
      "|              B02875|2021-06-01 00:18:54|2021-06-01 00:26:14|          80|         256|      N|                B02875|\n",
      "|              B02875|2021-06-01 00:31:02|2021-06-01 00:36:39|         217|          17|      N|                B02875|\n",
      "|              B02875|2021-06-01 00:41:53|2021-06-01 01:07:32|          17|         265|      N|                B02875|\n",
      "|              B02875|2021-06-01 00:29:52|2021-06-01 00:54:41|         210|          76|      N|                B02875|\n",
      "|              B02510|2021-06-01 00:15:57|2021-06-01 00:39:36|         226|         213|      N|                  null|\n",
      "|              B02510|2021-06-01 00:11:59|2021-06-01 00:23:32|         191|           9|      N|                  null|\n",
      "|              B02510|2021-06-01 00:30:35|2021-06-01 00:45:35|          16|         250|      N|                  null|\n",
      "|              B02510|2021-06-01 00:49:01|2021-06-01 01:03:50|         182|         259|      N|                  null|\n",
      "|              B02510|2021-06-01 00:07:36|2021-06-01 00:21:13|         188|          72|      N|                  null|\n",
      "|              B02510|2021-06-01 00:25:48|2021-06-01 00:40:43|          39|          72|      N|                  null|\n",
      "|              B02510|2021-06-01 00:46:11|2021-06-01 00:53:39|          72|          35|      N|                  null|\n",
      "+--------------------+-------------------+-------------------+------------+------------+-------+----------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df = spark.read \\\n",
    "    .option(\"header\", \"true\") \\\n",
    "    .schema(schema) \\\n",
    "    .csv('fhvhv_tripdata_2021-06.csv')\n",
    "\n",
    "df.select (df.pickup_datetime, df.dropoff_datetime).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "ccda32f3",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "df = df.repartition(12)\n",
    "\n",
    "df.write.parquet('data/pq/fhvhv/2021/06/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "58989b55",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = spark.read.parquet('data/pq/fhvhv/2021/06/')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48b01d2f",
   "metadata": {},
   "source": [
    "**Q3**: How many taxi trips were there on February 15?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "f7489aea",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import functions as F\n",
    "import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "c9879eee",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "data": {
      "text/plain": [
       "452470"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "   df.filter((df.pickup_datetime >= datetime.datetime(2021, 6, 15))\n",
    "             &\n",
    "             (df.pickup_datetime < datetime.datetime(2021, 6, 16))\n",
    "            ) .count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "6c2500fd",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "data": {
      "text/plain": [
       "450872"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df \\\n",
    "    .withColumn('pickup_date', F.to_date(df.pickup_datetime)) \\\n",
    "    .filter(\"pickup_date = '2021-06-15'\") \\\n",
    "    .count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "dd7ae60d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/Dmitrii_Kalmanovich/spark/spark-3.3.2-bin-hadoop3/python/pyspark/sql/dataframe.py:229: FutureWarning: Deprecated in 2.0, use createOrReplaceTempView instead.\n",
      "  warnings.warn(\"Deprecated in 2.0, use createOrReplaceTempView instead.\", FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "df.registerTempTable('fhvhv_2021_06')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "6d47c147",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 4:=======================================>                   (2 + 1) / 3]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+\n",
      "|count(1)|\n",
      "+--------+\n",
      "|  450872|\n",
      "+--------+\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "spark.sql(\"\"\"\n",
    "SELECT\n",
    "    COUNT(1)\n",
    "FROM \n",
    "    fhvhv_2021_06\n",
    "WHERE\n",
    "    to_date(pickup_datetime) = '2021-06-15';\n",
    "\"\"\").show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae3f533b",
   "metadata": {},
   "source": [
    "**Q4**: Longest trip for each day"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "7befe422",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['dispatching_base_num',\n",
       " 'pickup_datetime',\n",
       " 'dropoff_datetime',\n",
       " 'PULocationID',\n",
       " 'DOLocationID',\n",
       " 'SR_Flag',\n",
       " 'Affiliated_base_number']"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "748da863",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+-------------------+-------------------+------------+------------+-------+----------------------+\n",
      "|dispatching_base_num|    pickup_datetime|   dropoff_datetime|PULocationID|DOLocationID|SR_Flag|Affiliated_base_number|\n",
      "+--------------------+-------------------+-------------------+------------+------------+-------+----------------------+\n",
      "|              B02617|2021-06-04 16:50:34|2021-06-04 17:01:18|         118|         109|      N|                B02617|\n",
      "|              B02875|2021-06-02 22:28:45|2021-06-02 22:37:28|         163|          79|      N|                B02875|\n",
      "|              B02871|2021-06-03 11:47:48|2021-06-03 11:52:23|         231|          13|      N|                B02871|\n",
      "|              B02888|2021-06-03 08:45:25|2021-06-03 09:00:12|           9|          92|      N|                B02888|\n",
      "|              B02510|2021-06-05 09:50:43|2021-06-05 10:06:53|          14|         133|      N|                  null|\n",
      "|              B02764|2021-06-03 22:55:50|2021-06-03 23:21:24|         152|          74|      N|                B02764|\n",
      "|              B02889|2021-06-02 03:15:48|2021-06-02 03:26:20|         220|         235|      N|                B02889|\n",
      "|              B02872|2021-06-01 11:50:42|2021-06-01 12:00:36|         162|         161|      N|                B02872|\n",
      "|              B02510|2021-06-04 06:51:45|2021-06-04 06:56:26|         206|         206|      N|                  null|\n",
      "|              B02835|2021-06-02 01:21:31|2021-06-02 01:50:23|          49|         182|      N|                B02835|\n",
      "|              B02510|2021-06-02 17:11:31|2021-06-02 18:18:32|         236|          89|      N|                  null|\n",
      "|              B02869|2021-06-01 18:48:20|2021-06-01 18:54:59|         151|          43|      N|                B02869|\n",
      "|              B02510|2021-06-02 16:16:53|2021-06-02 16:39:03|         181|         189|      N|                  null|\n",
      "|              B02510|2021-06-03 21:23:35|2021-06-03 21:33:33|         181|          89|      N|                  null|\n",
      "|              B02764|2021-06-01 06:51:24|2021-06-01 06:58:09|          86|          86|      N|                B02764|\n",
      "|              B02867|2021-06-04 18:26:09|2021-06-04 18:41:43|         162|         263|      N|                B02867|\n",
      "|              B02510|2021-06-01 10:21:49|2021-06-01 11:08:24|         151|          17|      N|                  null|\n",
      "|              B02682|2021-06-04 01:45:17|2021-06-04 01:53:16|         125|         164|      N|                B02682|\n",
      "|              B02875|2021-06-01 14:06:42|2021-06-01 14:33:53|         192|           7|      N|                B02875|\n",
      "|              B02510|2021-06-03 21:15:15|2021-06-03 21:21:24|         171|          16|      N|                  null|\n",
      "+--------------------+-------------------+-------------------+------------+------------+-------+----------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "907316e1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------------+-------------------+-------------------+\n",
      "|    pickup_datetime|   dropoff_datetime|      durationHours|\n",
      "+-------------------+-------------------+-------------------+\n",
      "|2021-06-01 00:02:41|2021-06-01 00:07:46|0.08472222222222223|\n",
      "|2021-06-01 00:16:16|2021-06-01 00:21:14|0.08277777777777778|\n",
      "|2021-06-01 00:27:01|2021-06-01 00:42:11|0.25277777777777777|\n",
      "|2021-06-01 00:46:08|2021-06-01 00:53:45|0.12694444444444444|\n",
      "|2021-06-01 00:45:42|2021-06-01 01:03:33|             0.2975|\n",
      "|2021-06-01 00:18:15|2021-06-01 00:25:47|0.12555555555555556|\n",
      "|2021-06-01 00:33:06|2021-06-01 00:42:46|0.16111111111111112|\n",
      "|2021-06-01 00:46:27|2021-06-01 00:56:50|0.17305555555555555|\n",
      "|2021-06-01 00:48:06|2021-06-01 01:04:10| 0.2677777777777778|\n",
      "|2021-06-01 00:18:54|2021-06-01 00:26:14|0.12222222222222222|\n",
      "|2021-06-01 00:31:02|2021-06-01 00:36:39|0.09361111111111112|\n",
      "|2021-06-01 00:41:53|2021-06-01 01:07:32|             0.4275|\n",
      "|2021-06-01 00:29:52|2021-06-01 00:54:41| 0.4136111111111111|\n",
      "|2021-06-01 00:15:57|2021-06-01 00:39:36|0.39416666666666667|\n",
      "|2021-06-01 00:11:59|2021-06-01 00:23:32|             0.1925|\n",
      "|2021-06-01 00:30:35|2021-06-01 00:45:35|               0.25|\n",
      "|2021-06-01 00:49:01|2021-06-01 01:03:50|0.24694444444444444|\n",
      "|2021-06-01 00:07:36|2021-06-01 00:21:13|0.22694444444444445|\n",
      "|2021-06-01 00:25:48|2021-06-01 00:40:43|0.24861111111111112|\n",
      "|2021-06-01 00:46:11|2021-06-01 00:53:39|0.12444444444444444|\n",
      "+-------------------+-------------------+-------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.select(df.pickup_datetime, df.dropoff_datetime) \\\n",
    ".withColumn('durationHours', (df.dropoff_datetime.cast('long') - df.pickup_datetime.cast('long') )/(60*60)) \\\n",
    ".show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "279d9161",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 36:=================================================>        (6 + 1) / 7]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------+------------------+\n",
      "|pickup_date|max(durationHours)|\n",
      "+-----------+------------------+\n",
      "| 2021-06-25|  66.8788888888889|\n",
      "| 2021-06-22|25.549722222222222|\n",
      "| 2021-06-27|19.980833333333333|\n",
      "| 2021-06-26|18.197222222222223|\n",
      "| 2021-06-23|16.466944444444444|\n",
      "+-----------+------------------+\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "df \\\n",
    "    .withColumn('durationHours', (df.dropoff_datetime.cast('long') - df.pickup_datetime.cast('long') )/(60*60)) \\\n",
    "    .withColumn('pickup_date', F.to_date(df.pickup_datetime)) \\\n",
    "    .groupBy('pickup_date') \\\n",
    "        .max('durationHours') \\\n",
    "    .orderBy('max(durationHours)', ascending=False) \\\n",
    "    .limit(5) \\\n",
    "    .show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "74cf0e8b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 42:======================================>                   (2 + 1) / 3]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------+------------------+\n",
      "|pickup_date|          duration|\n",
      "+-----------+------------------+\n",
      "| 2021-06-25|  66.8788888888889|\n",
      "| 2021-06-22|25.549722222222222|\n",
      "| 2021-06-27|19.980833333333333|\n",
      "| 2021-06-26|18.197222222222223|\n",
      "| 2021-06-23|16.466944444444444|\n",
      "| 2021-06-24|13.909722222222221|\n",
      "| 2021-06-04|             11.67|\n",
      "| 2021-06-20|10.984444444444444|\n",
      "| 2021-06-01|           10.2675|\n",
      "| 2021-06-28| 9.966388888888888|\n",
      "| 2021-06-18| 9.624444444444444|\n",
      "| 2021-06-08| 9.480277777777777|\n",
      "| 2021-06-11| 9.471666666666666|\n",
      "| 2021-06-15| 9.402222222222223|\n",
      "| 2021-06-03| 9.365833333333333|\n",
      "| 2021-06-19| 9.106944444444444|\n",
      "| 2021-06-30| 9.056111111111111|\n",
      "| 2021-06-09| 9.030277777777778|\n",
      "| 2021-06-17| 8.774166666666666|\n",
      "| 2021-06-29| 8.571666666666667|\n",
      "+-----------+------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "spark.sql(\"\"\"\n",
    "SELECT\n",
    "    to_date(pickup_datetime) AS pickup_date,\n",
    "       MAX((CAST(dropoff_datetime AS LONG) - CAST(pickup_datetime AS LONG)) / 3600) AS duration\n",
    "FROM \n",
    "    fhvhv_2021_06\n",
    "GROUP BY\n",
    "    1\n",
    "ORDER BY\n",
    "    2 DESC\n",
    "LIMIT 100;\n",
    "\"\"\").show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d915096b",
   "metadata": {},
   "source": [
    "**Q5**: Most frequent `dispatching_base_num`\n",
    "\n",
    "How many stages this spark job has?\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "25816aa2",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "[Stage 73:>                                                         (0 + 4) / 4]\r",
      "\r",
      "[Stage 73:==============>                                           (1 + 3) / 4]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+--------+\n",
      "|dispatching_base_num|count(1)|\n",
      "+--------------------+--------+\n",
      "|              B02510| 3233664|\n",
      "|              B02764|  965568|\n",
      "|              B02872|  882689|\n",
      "|              B02875|  685390|\n",
      "|              B02765|  559768|\n",
      "+--------------------+--------+\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "[Stage 74:===================================================>  (189 + 5) / 200]\r",
      "\r",
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "spark.sql(\"\"\"\n",
    "SELECT\n",
    "    dispatching_base_num,\n",
    "    COUNT(1)\n",
    "FROM \n",
    "    fhvhv_2021_02\n",
    "GROUP BY\n",
    "    1\n",
    "ORDER BY\n",
    "    2 DESC\n",
    "LIMIT 5;\n",
    "\"\"\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "a78f9fe3",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "[Stage 86:>                                                         (0 + 4) / 4]\r",
      "\r",
      "[Stage 86:=============================>                            (2 + 2) / 4]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+-------+\n",
      "|dispatching_base_num|  count|\n",
      "+--------------------+-------+\n",
      "|              B02510|3233664|\n",
      "|              B02764| 965568|\n",
      "|              B02872| 882689|\n",
      "|              B02875| 685390|\n",
      "|              B02765| 559768|\n",
      "+--------------------+-------+\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "[Stage 87:===========================================>          (161 + 5) / 200]\r",
      "\r",
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "df \\\n",
    "    .groupBy('dispatching_base_num') \\\n",
    "        .count() \\\n",
    "    .orderBy('count', ascending=False) \\\n",
    "    .limit(5) \\\n",
    "    .show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "f19b929b",
   "metadata": {},
   "outputs": [],
   "source": [
    "z_schema = types.StructType([    \n",
    "    types.StructField('LocationID', types.IntegerType(), True),\n",
    "    types.StructField('Borough', types.StringType(), True),\n",
    "    types.StructField('Zone', types.StringType(), True),\n",
    "    types.StructField('service_zone', types.StringType(), True)\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d10173a",
   "metadata": {},
   "source": [
    "**Q6**: Most common locations pair"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "74b7f664",
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_zones = spark.read.parquet('zones') #.schema(schema) \\\n",
    "df_zones = spark.read \\\n",
    "    .option(\"header\", \"true\") \\\n",
    "    .schema(z_schema) \\\n",
    "    .csv('./data/lookup/taxi_zone_lookup.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "57500594",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\"LocationID\",\"Borough\",\"Zone\",\"service_zone\"\r",
      "\r\n",
      "1,\"EWR\",\"Newark Airport\",\"EWR\"\r",
      "\r\n",
      "2,\"Queens\",\"Jamaica Bay\",\"Boro Zone\"\r",
      "\r\n",
      "3,\"Bronx\",\"Allerton/Pelham Gardens\",\"Boro Zone\"\r",
      "\r\n",
      "4,\"Manhattan\",\"Alphabet City\",\"Yellow Zone\"\r",
      "\r\n",
      "5,\"Staten Island\",\"Arden Heights\",\"Boro Zone\"\r",
      "\r\n",
      "6,\"Staten Island\",\"Arrochar/Fort Wadsworth\",\"Boro Zone\"\r",
      "\r\n",
      "7,\"Queens\",\"Astoria\",\"Boro Zone\"\r",
      "\r\n",
      "8,\"Queens\",\"Astoria Park\",\"Boro Zone\"\r",
      "\r\n",
      "9,\"Queens\",\"Auburndale\",\"Boro Zone\"\r",
      "\r\n"
     ]
    }
   ],
   "source": [
    "!head ./data/lookup/taxi_zone_lookup.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "81642d3b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- LocationID: integer (nullable = true)\n",
      " |-- Borough: string (nullable = true)\n",
      " |-- Zone: string (nullable = true)\n",
      " |-- service_zone: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_zones.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "4f460dda",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['hvfhs_license_num',\n",
       " 'dispatching_base_num',\n",
       " 'pickup_datetime',\n",
       " 'dropoff_datetime',\n",
       " 'PULocationID',\n",
       " 'DOLocationID',\n",
       " 'SR_Flag']"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "ad8f0101",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_zones.registerTempTable('zones')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "6f738414",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 52:======================================>                   (2 + 1) / 3]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------------+--------+\n",
      "|         pu_do_pair|count(1)|\n",
      "+-------------------+--------+\n",
      "|Crown Heights North|  231279|\n",
      "|       East Village|  221244|\n",
      "|        JFK Airport|  188867|\n",
      "|     Bushwick South|  187929|\n",
      "|      East New York|  186780|\n",
      "+-------------------+--------+\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "spark.sql(\"\"\"\n",
    "SELECT\n",
    "    CONCAT(pul.Zone) AS pu_do_pair,\n",
    "    COUNT(1)\n",
    "FROM \n",
    "    fhvhv_2021_06 fhv LEFT JOIN zones pul ON fhv.PULocationID = pul.LocationID\n",
    "                      --LEFT JOIN zones dol ON fhv.DOLocationID = dol.LocationID\n",
    "GROUP BY \n",
    "    1\n",
    "ORDER BY\n",
    "    2 DESC\n",
    "LIMIT 5;\n",
    "\"\"\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4b754d1",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
